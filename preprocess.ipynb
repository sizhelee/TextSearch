{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入需要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 将服务器端每一条新闻转化成txt格式存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = \"./server_files\"\n",
    "if not os.path.exists(dirs):\n",
    "    os.mkdir(dirs)\n",
    "\n",
    "passage_dirs = \"./server_files/news\"\n",
    "if not os.path.exists(passage_dirs):\n",
    "    os.mkdir(passage_dirs)\n",
    "\n",
    "df = pd.read_csv(\"./data/all_news.csv\")\n",
    "for item in df.iloc():\n",
    "    with open(\"{}/{}.txt\".format(passage_dirs, item.id), \"w\") as f:\n",
    "        f.write(item.title)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(item.body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据集，提取词根构建词典，保存词频信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import json\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "dic = {}\n",
    "vocab = []\n",
    "\n",
    "for i in df.body:\n",
    "    i = i.strip().translate(str.maketrans('', '', string.punctuation))\n",
    "    tokenize = nltk.word_tokenize(i)\n",
    "    for word in tokenize:\n",
    "        lemma = lemmatizer.lemmatize(word.lower())\n",
    "        if lemma in dic.keys():\n",
    "            dic[lemma] += 1\n",
    "        else:\n",
    "            dic[lemma] = 1\n",
    "            vocab.append(lemma)\n",
    "\n",
    "dic = sorted(dic.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "json_dic = json.dumps(dict(dic))\n",
    "with open(\"./server_files/vocab.json\", \"w\") as f:\n",
    "    f.write(json_dic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建TF-IDF向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2096\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>word</th>\n",
       "      <th>TF</th>\n",
       "      <th>IDF</th>\n",
       "      <th>TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>6.954639</td>\n",
       "      <td>0.016921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>profits</td>\n",
       "      <td>0.012165</td>\n",
       "      <td>3.504651</td>\n",
       "      <td>0.042636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>at</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.250225</td>\n",
       "      <td>0.001826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.010119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>media</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>0.006746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834792</th>\n",
       "      <td>Losing yourself in online gaming</td>\n",
       "      <td>2224</td>\n",
       "      <td>2917</td>\n",
       "      <td>was</td>\n",
       "      <td>0.007187</td>\n",
       "      <td>0.237439</td>\n",
       "      <td>0.001706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834793</th>\n",
       "      <td>Losing yourself in online gaming</td>\n",
       "      <td>2224</td>\n",
       "      <td>2918</td>\n",
       "      <td>the</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834794</th>\n",
       "      <td>Losing yourself in online gaming</td>\n",
       "      <td>2224</td>\n",
       "      <td>2919</td>\n",
       "      <td>days</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>2.529792</td>\n",
       "      <td>0.003463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834795</th>\n",
       "      <td>Losing yourself in online gaming</td>\n",
       "      <td>2224</td>\n",
       "      <td>2920</td>\n",
       "      <td>!</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>7.647786</td>\n",
       "      <td>0.002617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834796</th>\n",
       "      <td>Losing yourself in online gaming</td>\n",
       "      <td>2224</td>\n",
       "      <td>2921</td>\n",
       "      <td>LOL</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>7.647786</td>\n",
       "      <td>0.002617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>834797 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title  level_0  level_1       word  \\\n",
       "0       Ad sales boost Time Warner profit        0        0  Quarterly   \n",
       "1       Ad sales boost Time Warner profit        0        1    profits   \n",
       "2       Ad sales boost Time Warner profit        0        2         at   \n",
       "3       Ad sales boost Time Warner profit        0        3         US   \n",
       "4       Ad sales boost Time Warner profit        0        4      media   \n",
       "...                                   ...      ...      ...        ...   \n",
       "834792   Losing yourself in online gaming     2224     2917        was   \n",
       "834793   Losing yourself in online gaming     2224     2918        the   \n",
       "834794   Losing yourself in online gaming     2224     2919       days   \n",
       "834795   Losing yourself in online gaming     2224     2920          !   \n",
       "834796   Losing yourself in online gaming     2224     2921        LOL   \n",
       "\n",
       "              TF       IDF    TF-IDF  \n",
       "0       0.002433  6.954639  0.016921  \n",
       "1       0.012165  3.504651  0.042636  \n",
       "2       0.007299  0.250225  0.001826  \n",
       "3       0.007299  1.386294  0.010119  \n",
       "4       0.002433  2.772589  0.006746  \n",
       "...          ...       ...       ...  \n",
       "834792  0.007187  0.237439  0.001706  \n",
       "834793  0.035250  0.000000  0.000000  \n",
       "834794  0.001369  2.529792  0.003463  \n",
       "834795  0.000342  7.647786  0.002617  \n",
       "834796  0.000342  7.647786  0.002617  \n",
       "\n",
       "[834797 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/all_news.csv\")\n",
    "\n",
    "split_words = df['body'].str.split(\n",
    "    ' ', expand=True).stack().rename('word').reset_index()\n",
    "new_data = pd.merge(df['title'], split_words,\n",
    "                    left_index=True, right_on='level_0')\n",
    "\n",
    "def tf(x):\n",
    "    t = dict(x['word'].value_counts()/x['word'].value_counts().sum())\n",
    "    return t\n",
    "\n",
    "\n",
    "data_tf = new_data.groupby(\"title\").apply(tf)\n",
    "new_data['TF'] = new_data.apply(lambda x: data_tf[x[\"title\"]][x['word']], axis=1)\n",
    "\n",
    "\n",
    "def idf(x):\n",
    "    return np.log(df[\"title\"].nunique()/x['title'].nunique())\n",
    "\n",
    "\n",
    "data_idf = dict(new_data.groupby('word').apply(lambda x: idf(x)))\n",
    "\n",
    "new_data['IDF'] = new_data.apply(lambda x: data_idf[x['word']], axis=1)\n",
    "new_data['TF-IDF'] = new_data.apply(lambda x: x['TF']*x['IDF'], axis=1)\n",
    "new_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算文档向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'body'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\PKU\\21to22spring\\Python程序设计与数据科学导论-胡俊峰\\TextSearch\\preprocess.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PKU/21to22spring/Python%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AF%BC%E8%AE%BA-%E8%83%A1%E4%BF%8A%E5%B3%B0/TextSearch/preprocess.ipynb#ch0000008?line=0'>1</a>\u001b[0m max_len \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PKU/21to22spring/Python%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AF%BC%E8%AE%BA-%E8%83%A1%E4%BF%8A%E5%B3%B0/TextSearch/preprocess.ipynb#ch0000008?line=1'>2</a>\u001b[0m max_idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/PKU/21to22spring/Python%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AF%BC%E8%AE%BA-%E8%83%A1%E4%BF%8A%E5%B3%B0/TextSearch/preprocess.ipynb#ch0000008?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, i \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(new_data\u001b[39m.\u001b[39;49mbody):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PKU/21to22spring/Python%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AF%BC%E8%AE%BA-%E8%83%A1%E4%BF%8A%E5%B3%B0/TextSearch/preprocess.ipynb#ch0000008?line=3'>4</a>\u001b[0m     word_len \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PKU/21to22spring/Python%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E5%AF%BC%E8%AE%BA-%E8%83%A1%E4%BF%8A%E5%B3%B0/TextSearch/preprocess.ipynb#ch0000008?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m word_len \u001b[39m>\u001b[39m max_len:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py:5583\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/84350/anaconda3/envs/tensorflow/lib/site-packages/pandas/core/generic.py?line=5575'>5576</a>\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   <a href='file:///c%3A/Users/84350/anaconda3/envs/tensorflow/lib/site-packages/pandas/core/generic.py?line=5576'>5577</a>\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   <a href='file:///c%3A/Users/84350/anaconda3/envs/tensorflow/lib/site-packages/pandas/core/generic.py?line=5577'>5578</a>\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   <a href='file:///c%3A/Users/84350/anaconda3/envs/tensorflow/lib/site-packages/pandas/core/generic.py?line=5578'>5579</a>\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   <a href='file:///c%3A/Users/84350/anaconda3/envs/tensorflow/lib/site-packages/pandas/core/generic.py?line=5579'>5580</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   <a href='file:///c%3A/Users/84350/anaconda3/envs/tensorflow/lib/site-packages/pandas/core/generic.py?line=5580'>5581</a>\u001b[0m ):\n\u001b[0;32m   <a href='file:///c%3A/Users/84350/anaconda3/envs/tensorflow/lib/site-packages/pandas/core/generic.py?line=5581'>5582</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> <a href='file:///c%3A/Users/84350/anaconda3/envs/tensorflow/lib/site-packages/pandas/core/generic.py?line=5582'>5583</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'body'"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "max_idx = 0\n",
    "for idx, i in enumerate(df.body):\n",
    "    word_len = i.count(\" \")+1\n",
    "    if word_len > max_len:\n",
    "        max_len = word_len\n",
    "        max_idx = idx\n",
    "max_len, max_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2096\n",
      "(2096, 4374)\n",
      "(2096, 1000)\n"
     ]
    }
   ],
   "source": [
    "feats = []\n",
    "group = list(new_data.groupby(\"title\"))\n",
    "print(len(group))\n",
    "\n",
    "for item in group:\n",
    "    feat = np.array(item[1][\"TF-IDF\"])\n",
    "    feat = np.pad(feat, (0, max_len-feat.shape[0]), 'constant', constant_values=(0,0))\n",
    "    feats.append(feat)\n",
    "\n",
    "feats = np.vstack(feats)\n",
    "print(feats.shape)\n",
    "\n",
    "pca = PCA(n_components=1000)\n",
    "pca.fit(feats)\n",
    "feats_new = pca.transform(feats)\n",
    "print(feats_new.shape)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9989796ec7fb59f7bf2a8298c492019b8d9576723ce78daf27250f6c9a9a8e17"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
